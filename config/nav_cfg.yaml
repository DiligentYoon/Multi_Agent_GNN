
ray:
  num_cpus: 6
  num_workers: 6

# Environment Settings
env:
  seed: 42
  physics_dt: 0.1
  device: "cpu"
  num_agent: 3
  max_velocity: 0.3
  max_yaw_rate: 1.0 # radians
  max_acceleration: 0.1

  fov: 120 # degrees
  sensor_range: 0.3 # meters
  num_rays: 61

  map:
    height: 1.0
    width: 5.0
    resolution: 0.01 
    map_representation:
      free: 0
      unknown: 1
      occupied: 2
      goal: 3
      start: 4
      frontier: 5

  controller:
    max_obs: 0
    max_agents: 0
    d_max: 0
    d_safe: 0
    a_max: 0
    w_max: 0
    v_max: 0
    gamma_c1: 1.5
    gamma_c2: 1.5
    gamma_a1: 1.5
    gamma_a2: 1.5
    gamma_conn1: 1.5
    gamma_conn2: 1.0
    w_slack: 5000

  curriculum:
    demo:
      demo_rate: 0.9
      start_rate: 0.9
      end_rate: 0.1
      


# Agent Settings
agent:
  batch_size: 512
  minimum_buffer_size: 1000
  gradient_steps: 1

  discount_factor: 0.99
  polyak: 0.005

  learning_rate: 1e-5
  entropy_learning_rate: 5e-4
  learning_rate_scheduler: null
  learning_rate_scheduler_kwargs: {}

  grad_norm_clip: 0.5

  buffer:
    replay_size: 100000

  experiment:
    directory: "MARL"
    experiment_name: ""
    write_interval: auto
    checkpoint_interval: auto

model:

  feature_extractor:
    common:
      hidden: 128
    teammate:
      feature_dim: 10
    region:
      feature_dim: 10
    obstacle:
      feature_dim: 10
    num_group: 3


  actor:
    type: "Gaussian"
    hidden: [128, 64]
  
  critic:
    hidden: [128, 64]
    
# Training Settings
train:
  max_episode: 1000
  timesteps: 5000000